# ğŸ›¡ï¸ End-to-End Phishing URL Detection System  
### Production-Grade Machine Learning System with Flask, MongoDB, MLOps Pipelines & Docker

---

## ğŸ“Œ Executive Summary

Phishing attacks remain one of the most common and damaging cybersecurity threats, exploiting human trust through malicious URLs embedded in emails, messages, and fake websites.

This project is a **full-stack, production-oriented Phishing URL Detection System** that:

- Detects whether a URL is **phishing or legitimate**
- Implements a **complete ML lifecycle**
- Uses **clean architecture and modular pipelines**
- Integrates **Flask for inference delivery**
- Stores and ingests data from **MongoDB**
- Is **Dockerized** and **CI/CD-ready**
- Follows **industry MLOps and software engineering practices**

This is **not a notebook-only ML project**.  
It is designed as a **deployable, scalable system**.

---

## ğŸ¯ Problem Statement

Phishing websites mimic trusted domains to steal credentials, financial data, and personal information.

Traditional rule-based systems fail because:
- Attack patterns evolve rapidly
- Manual rules do not scale
- Static blacklists become obsolete

### Solution
Use **machine learning** to classify URLs using:
- URL structure features
- Domain-based signals
- SSL and security indicators
- Redirection and behavioral patterns
- Statistical and reputation-based features

---

## ğŸ§  Key Design Goals

- End-to-end automation
- Separation of concerns
- Reproducibility
- Config-driven ML pipelines
- Production-grade inference
- Interview-ready architecture

---

## ğŸ—ï¸ High-Level Architecture

Client (Browser / CSV Upload)
|
v
+------------------+
| Flask App |
| (app.py) |
+------------------+
|
v
+--------------------------+
| Prediction Pipeline |
| predict_pipeline.py |
+--------------------------+
|
v
+--------------------------+
| Preprocessor + Model |
| preprocessing.pkl |
| model.pkl |
+--------------------------+


---

## ğŸ“ Repository Structure



PHISHING-CLASSIFIER/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ model.pkl
â”‚
â”œâ”€â”€ config/
â”‚ â”œâ”€â”€ training_schema.json
â”‚ â””â”€â”€ model.yaml
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ pipeline/
â”‚ â”‚ â”œâ”€â”€ train_pipeline.py
â”‚ â”‚ â””â”€â”€ predict_pipeline.py
â”‚ â”‚
â”‚ â”œâ”€â”€ components/
â”‚ â”‚ â”œâ”€â”€ data_ingestion.py
â”‚ â”‚ â”œâ”€â”€ data_validation.py
â”‚ â”‚ â”œâ”€â”€ data_transformation.py
â”‚ â”‚ â””â”€â”€ model_trainer.py
â”‚ â”‚
â”‚ â”œâ”€â”€ data_access/
â”‚ â”‚ â””â”€â”€ phising_data.py
â”‚ â”‚
â”‚ â”œâ”€â”€ utils/
â”‚ â”‚ â”œâ”€â”€ main_utils.py
â”‚ â”‚ â”œâ”€â”€ logger.py
â”‚ â”‚ â””â”€â”€ exception.py
â”‚
â”œâ”€â”€ templates/
â”‚ â””â”€â”€ prediction.html
â”‚
â”œâ”€â”€ static/css/
â”‚ â””â”€â”€ style.css
â”‚
â”œâ”€â”€ logs/
â”œâ”€â”€ artifacts/
â”œâ”€â”€ prediction_artifacts/
â””â”€â”€ predictions/


---

## ğŸŒ Flask Application Layer

Flask acts as a **thin orchestration layer**.

### Routes

| Route | Method | Description |
|-----|------|------------|
| `/` | GET | Load prediction UI |
| `/train` | GET | Trigger full training pipeline |
| `/predict` | POST | Upload CSV and download predictions |

No ML logic is written inside Flask routes.

---

## ğŸ” Training Pipeline

**File:** `src/pipeline/train_pipeline.py`

Execution order:

run_pipeline()
â”œâ”€â”€ Data Ingestion
â”œâ”€â”€ Data Validation
â”œâ”€â”€ Data Transformation
â””â”€â”€ Model Training


Each stage is:
- Independent
- Logged
- Exception-safe
- Artifact-producing

---

## ğŸ“¥ Data Ingestion

**Source:** MongoDB  
**File:** `data_ingestion.py`

Responsibilities:
- Connect to MongoDB
- Export collections
- Save raw CSV files to artifacts directory

---

## âœ… Data Validation

**File:** `data_validation.py`  
**Config:** `training_schema.json`

Validations:
- File name pattern
- Timestamp format
- Column count
- Missing value checks

Validated and invalid data are separated physically.

---

## ğŸ”„ Data Transformation

**File:** `data_transformation.py`

Steps:
- Merge validated batches
- Remove unwanted spaces
- Handle missing values
- Encode target labels
- Handle class imbalance (RandomOverSampler)
- Train-test split
- Save preprocessing object

---

## ğŸ§  Model Training & Selection

**File:** `model_trainer.py`

Models evaluated:
- Logistic Regression
- Gaussian Naive Bayes
- XGBoost Classifier

Process:
1. Train all models
2. Compare accuracy
3. Select best model
4. Hyperparameter tuning using GridSearchCV
5. Final training
6. Save model artifact

All hyperparameters are defined in `config/model.yaml`.

---

## ğŸ“¦ Model Artifact Design

The saved model includes:
- Preprocessing object
- Trained ML model

This ensures **trainingâ€“inference consistency**.

---

## ğŸ”® Prediction Pipeline

**File:** `predict_pipeline.py`

Flow:
1. CSV upload
2. Save input file
3. Load model + preprocessor
4. Transform features
5. Generate predictions
6. Save output CSV
7. Download predictions

---

## ğŸ“Š Exploratory Data Analysis (EDA)

![alt text](image.png)

EDA Insights:

URL-based indicators are dominant

Binary features strongly influence predictions

Behavioral and domain signals improve accuracy

ğŸ“ˆ Feature Categories
Category	Examples
URL Structure	Length, IP usage, symbols
Domain Info	Age, DNS record
Security	SSL state, HTTPS token
Behavior	Redirects, popups
Reputation	Traffic, page rank
ğŸªµ Logging & Observability

Centralized logging with:

Timestamped logs

File-based storage

Structured messages

Enables debugging and production monitoring.

âŒ Exception Handling

Custom exception system captures:

File name

Line number

Error message

Full traceback

ğŸ³ Dockerization

Dockerfile:

FROM python:3.8-slim-buster
WORKDIR /app
COPY . /app
RUN pip install -r requirements.txt
CMD ["python3","app.py"]


Benefits:

Reproducible environment

Easy deployment

Cloud ready

ğŸš€ Run Locally
git clone https://github.com/your-username/phishing-classifier.git
cd phishing-classifier
pip install -r requirements.txt
python app.py


Open:
http://127.0.0.1:5050

ğŸ§ª Sample Input
having_IP_Address,URL_Length,...
1,54,...

ğŸ“¤ Output
...,Result
...,phishing
...,safe

ğŸ§  Interview Talking Points

Modular ML pipelines

Artifact-driven workflows

Flask orchestration

Config-driven modeling

Data validation strategies

Dockerized ML systems

ğŸ”® Future Enhancements

MLflow integration

Async training

REST APIs

Cloud deployment

Monitoring dashboards

Drift detection

â­ Why This Project Matters

This repository demonstrates:

Real-world ML engineering

Production architecture

MLOps best practices

Interview-ready system design

ğŸ¤ Contributing

Fork â†’ Create branch â†’ Submit PR ğŸš€

â­ Star This Repo

If you found this useful, give it a â­
It helps others discover quality ML projects.



'''pip install -e .  ''' to run setup.py
